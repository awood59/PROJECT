dfSimi=daisy(df[,c(3:6)],metric = "euclidean",
stand=TRUE) # standardizing
# Apply the clustering technique:
dfClus=hclust(dfSimi,method = 'complete') # different linkage
# Determine the adequate amount of clusters:
# General plot
plot(dfClus,cex=0.5)
plot(dfClus,cex=0.3)
rect.hclust(dfClus, k = 4,border = c('orange','blue','red','green'))
# See numerically with 4
dfsil4=silhouette(cutree(dfClus, k = 4), dfSimi)
clust4solution=data.frame(matrix(dfsil4,ncol = 3,dimnames =dimnames(dfsil4)))
row.names(clust4solution)=df$Country
(bad4=clust4solution[clust4solution$sil_width<0,])
#Include the cluster information into your original data.
# saving solution chosen
solution=clust4solution
# creating country column
solution$Country=row.names(clust4solution)
row.names(solution)=NULL # resetting rownames
# merging
dfUpdated=merge(df,solution)
# You can see a different matrix plot:
palette=c('blue','orange','red','black')
scatterplotMatrix(dfUpdated[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,groups = dfUpdated$cluster,col = palette,legend.plot=F)
corruptLink='https://raw.githubusercontent.com/EvansDataScience/data/master/corruption.csv'
econoLink='https://raw.githubusercontent.com/EvansDataScience/data/master/economic.csv'
enviroLink='https://raw.githubusercontent.com/EvansDataScience/data/master/environment.csv'
pressLink='https://raw.githubusercontent.com/EvansDataScience/data/master/pressfreedom.csv'
corrupt=read.csv(corruptLink,stringsAsFactors = F)
econo=read.csv(econoLink,stringsAsFactors = F)
enviro=read.csv(enviroLink,stringsAsFactors = F)
press=read.csv(pressLink,stringsAsFactors = F)
indexes1=merge(corrupt,econo)
indexes2=merge(press,enviro)
indexes=merge(indexes1,indexes2)
str(indexes)
summary(indexes)
library(psych)
install.packages("psych")
library(psych)
indexes$scorepressOK=reverse.code(-1,indexes$scorepress)
indexes$presscat=as.factor(indexes$presscat)
indexes$presscat=as.factor(indexes$presscat)
indexes$environmentCat=as.factor(indexes$environmentCat)
hist(indexes$environment)
explanans=names(indexes)[c(3,4,9)]
for (x in explanans){
par=cbind(indexes[,x],indexes$environment)
p=cor.test(indexes[,x],indexes$environment)
print(paste("Pearson:",p$estimate," - Is significative?",p$p.value<0.05))
}
cor(indexes[explanans])
row.names(indexes)=indexes$Country
LinRegEPI = lm(environment ~ corruptionIndex + scoreEconomy + scorepressOK,
data = indexes)
summary(LinRegEPI)
results=coef(summary(LinRegEPI))
data.frame(Coefficient=results[,1],Significant=results[,4]<0.05)
summary(LinRegEPI)$adj.r.squared
library(car)
influencePlot(LinRegEPI,
id.method="noteworthy",
id.n=3,
main="Identifying outliers",
sub="Circle size is proportial to Cook's Distance" )
library(MASS)
LinRegEPI_R = rlm(environment ~ corruptionIndex + scoreEconomy + scorepressOK,
data = indexes)
library(MASS)
LinRegEPI_R = rlm(environment ~ corruptionIndex + scoreEconomy + scorepressOK,
data = indexes)
indexes$presscat <- relevel(indexes$presscat, ref = "High")
LinRegEPI_catX <- lm(environment ~ corruptionIndex + scoreEconomy + presscat,
data = indexes)
results=coef(summary(LinRegEPI_catX))
data.frame(Coefficient=results[,1],Significant=results[,4]<0.05)
summary(LinRegEPI_catX)$adj.r.squared
barplot(table(indexes$environmentCat))
LogitEPI_a =glm(environmentCat ~ corruptionIndex + scoreEconomy + scorepressOK,
data = indexes,
family = binomial())
LogitEPI_a =glm(environmentCat ~ corruptionIndex + scoreEconomy + scorepressOK,
data = indexes,
family = binomial())
results=coef(summary(LogitEPI_a))
data.frame(CoefficientExp=exp(results[,1]),Significant=results[,4]<0.05)
LogitEPI_b =glm(environmentCat ~ corruptionIndex + scoreEconomy + presscat,
data = indexes,
family = binomial())
results=coef(summary(LogitEPI_b))
data.frame(CoefficientExp=exp(results[,1]),Significant=results[,4]<0.05)
if (LogitEPI_a$aic < LogitEPI_b$aic){
print("model 'a' is better")
}else{print("model 'b' is better")}
actualValues=indexes$environmentCat
predictedValues=predict(LogitEPI_a, type = 'response')
library(InformationValue)
install.packages("InformationValue")
library(InformationValue)
cm=confusionMatrix(actualValues, predictedValues)
row.names(cm)=c('PredictedNegative','PredictedPositive')
colnames(cm)=c('ActualNegative','ActualPositive')
cm
misClassError(actualValues, predictedValues)
plotROC(actualValues, predictedValues)
TruePositive=cm['PredictedPositive','ActualPositive']
TrueNegative=cm['PredictedNegative','ActualNegative']
FalsePositive=cm['PredictedPositive','ActualNegative']
FalseNegative=cm['PredictedNegative','ActualPositive']
sensitivity(actualValues, predictedValues)
specificity(actualValues, predictedValues)
indexes$presscat <- relevel(indexes$presscat, ref = "Low")
LinRegEPI_catX <- lm(environment ~ corruptionIndex + scoreEconomy + presscat,
data = indexes)
results=coef(summary(LinRegEPI_catX))
data.frame(Coefficient=results[,1],Significant=results[,4]<0.05)
knitr::opts_chunk$set(echo = TRUE)
library(car)
scatterplotMatrix(X2017WorldHappiness[,c(2:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
library(car)
scatterplotMatrix(X2017WorldHappiness[,c(1:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
library(car)
scatterplotMatrix(X2017WorldHappiness[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
str(df[,c(1:6)])
library(cluster)
dfSimi=daisy(df[,c(1:6)],metric = "euclidean",
stand=TRUE) # standardizing
library(cluster)
dfSimi=daisy(df[,c(2:6)],metric = "euclidean",
stand=TRUE) # standardizing
row.names(df)=df$Country
str(df[,c(1:6)])
plot(dfClus,cex=0.3)
rect.hclust(dfClus, k = 4,border = c('orange','blue','red','green'))
library(readxl)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/blob/gh-pages/2017WorldHappiness.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')  # file will be downloaded temporarily
library(car)
scatterplotMatrix(X2017WorldHappiness[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
df=X2017WorldHappiness
length(df$Country)==length(unique(df$Country))
row.names(df)=df$Country
str(df[,c(1:6)])
library(cluster)
dfSimi=daisy(df[,c(2:6)],metric = "euclidean",
stand=TRUE) # standardizing
# input is: similary matrix
dfClus=hclust(dfSimi,method = 'average') # linkage is 'average'
# General plot
plot(dfClus,cex=0.5)
plot(dfClus,cex=0.3)
rect.hclust(dfClus, k = 4,border = c('orange','blue','red','green'))
# with 4
dfsil4=silhouette(cutree(dfClus, k = 3), dfSimi)
clust4solution=data.frame(matrix(dfsil4,ncol = 3,dimnames =dimnames(dfsil4)))
row.names(clust4solution)=df$Country
(bad4=clust4solution[clust4solution$sil_width<0,])
# with 5
dfsil5=silhouette(cutree(dfClus, k = 4), dfSimi)
clust5solution=data.frame(matrix(dfsil5,ncol = 3,dimnames =dimnames(dfsil5)))
row.names(clust5solution)=df$Country
(bad5=clust5solution[clust5solution$sil_width<0,])
intersect(row.names(bad4),row.names(bad5))
palette=c('blue','orange','red','black')
scatterplotMatrix(dfUpdated[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,groups = dfUpdated$cluster,col = palette,legend.plot=F)
hist(log(df[,7]))
# Produce a similarity matrix:
library(cluster)
dfSimi=daisy(df[,c(3:6)],metric = "euclidean",
stand=TRUE) # standardizing
# Apply the clustering technique:
dfClus=hclust(dfSimi,method = 'complete') # different linkage
# Determine the adequate amount of clusters:
# General plot
plot(dfClus,cex=0.5)
plot(dfClus,cex=0.3)
rect.hclust(dfClus, k = 4,border = c('orange','blue','red','green'))
# See numerically with 4
dfsil4=silhouette(cutree(dfClus, k = 4), dfSimi)
clust4solution=data.frame(matrix(dfsil4,ncol = 3,dimnames =dimnames(dfsil4)))
row.names(clust4solution)=df$Country
(bad4=clust4solution[clust4solution$sil_width<0,])
#Include the cluster information into your original data.
# saving solution chosen
solution=clust4solution
# creating country column
solution$Country=row.names(clust4solution)
row.names(solution)=NULL # resetting rownames
# merging
dfUpdated=merge(df,solution)
# You can see a different matrix plot:
palette=c('blue','orange','red','black')
scatterplotMatrix(dfUpdated[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,groups = dfUpdated$cluster,col = palette,legend.plot=F)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
library(readxl)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/blob/gh-pages/Occupational_Employment_and_Wage_Estimates.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')  # file will be downloaded temporarily
View(solution)
View(results)
View(press)
View(par)
library(readxl)
Occupational_Employment_and_Wage_Estimates <- read_excel("~/Desktop/Occupational_Employment_and_Wage_Estimates.xlsx")
View(Occupational_Employment_and_Wage_Estimates)
library(car)
scatterplotMatrix(occupationalStatus[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
View(Occupational_Employment_and_Wage_Estimates)
library(car)
scatterplotMatrix(Occupational_Employment_and_Wage_Estimates[,c(2:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
library(car)
scatterplotMatrix(Occupational_Employment_and_Wage_Estimates[,c(1:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
library(car)
scatterplotMatrix(Occupational_Employment_and_Wage_Estimates[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
library(car)
scatterplotMatrix(Occupational_Employment_and_Wage_Estimates[,c(3:12)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
summary(Occupational_Employment_and_Wage_Estimates)
token='&$$app_token=qkzOjPpAsJDHAxBVNro7U82j5'
token='&$$app_token=qkzOjPpAsJDHAxBVNro7U82j5'
compressedMap= 'https://github.com/awood59/PROJECT/raw/master/tl_2013_53_unsd.zip'
library(utils)
temp=tempfile()
download.file(compressedMap, temp)
unzip(temp)
(maps=list.files(pattern = 'shp'))
library(rgdal)
install.packages("rgdal")
library(rgdal)
wazipMap <- rgdal::readOGR("tl_2013_53_unsd.shp",stringsAsFactors=F)
plot(wazipMap,col='black')
names(wazipMap)
plot(wazipMap,col='black')
plot(wazipMap,col='pink')
EnrollmentLink= 'https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx'
GradLink= 'https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx'
enrollment=read.csv(EnrollmentLink,stringsAsFactors = F)
enrollment=read_xlsx(EnrollmentLink,stringsAsFactors = F)
indexes1=merge(EnrollmentLink,GradLink)
View(indexes1)
str(indexes)
indexes2=merge(EnrollmentLink,GradLink)
indexes3=merge(EnrollmentLink,GradLink)
str(indexes3)
View(indexes1)
library(readxl)
Grads2015 <- read_excel("~/Desktop/Grads2015.xlsx")
View(Grads2015)
library(readxl)
EnrollmentWA <- read_excel("~/Desktop/EnrollmentWA.xlsx")
View(EnrollmentWA)
indexes3=merge(EnrollmentWA,Grads2015)
str(indexes3)
summary(indexes3)
GradLink='https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx'
EnrollmentLink='https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx'
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
indexes3=merge(EnrollmentLink,GradLink)
str(indexes3)
str(indexes3)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
GradLink = read_excel(temp, sheet =1)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
EnrollmentLink = read_excel(temp, sheet =1)
indexes3=merge(EnrollmentLink,GradLink)
str(indexes3)
summary(indexes3)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
GradLink = read_excel(temp, sheet =1)
head(GradLink,2)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
EnrollmentLink = read_excel(temp, sheet =1)
head(EnrollmentLink,2)
indexes3=merge(EnrollmentLink,GradLink)
str(indexes3)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Grad = read_excel(temp, sheet =1)
head(Grad,2)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Grad = read_excel(temp, sheet =1)
head(Grad,2)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Enrollment = read_excel(temp, sheet =1)
head(Enrollment,2)
names(Enrollment)
names(Grad)
table(Enrollment$`District Code`)
table(Grad$`Dist`)
gradenr=merge(Enrollment,Grad,by.x='District Code',by.y="Dist" )
Grad=Grad[,c(1,2,3,4,20)]
Enrollment=Enrollment[,c(1,2,3,4,20)]
gradenr=merge(Enrollment,Grad,by.x='District Code',by.y="Dist" )
View(gradenr)
dataLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv'
theData=read.csv(dataLink,stringsAsFactors = F,strip.white = T)
names(theData)
table(theData$STATE)
WAData=theData[theData$STATE=='Washington',]
row.names(WAData)=NULL
WAData$NAME
library(stringr)
(WAData$NAMEbad=unlist(lapply(WAData$NAME,word,-1)))
WAData$NAMEOK=NA
for (pos in 1:nrow(WAData)){
if(WAData$NAMEbad[pos]!="DISTRICT"){
cleanValue=sub(WAData$NAMEbad[pos],'',WAData$NAME[pos])
WAData$NAMEOK[pos]=trimws(cleanValue)
}else{WAData$NAMEOK[pos]=WAData$NAME[pos]}
}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
WAData[word(WAData$NAMEOK,-1)=='DIST',]
WAData$NAMEbad=unlist(lapply(WAData$NAMEOK,word,-1))
for (pos in 1:nrow(WAData)){
if (WAData$NAMEbad[pos]=='DIST'){
cleanValue=sub("DIST",'DISTRICT',WAData$NAMEOK[pos])
WAData$NAMEOK[pos]=trimws(cleanValue)
}
}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
(lastBad=names(table(unlist(lapply(WAData$NAMEOK,word,-1))))[-c(4,5)])
for (pos in 1:nrow(WAData)){
if (WAData$NAMEbad[pos]%in% lastBad){
cleanValue=sub(WAData$NAMEbad[pos],'',WAData$NAMEOK[pos])
WAData$NAMEOK[pos]=trimws(cleanValue)
}
}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
WAData[word(WAData$NAMEOK,-1)=='C',]
WAData[word(WAData$NAMEOK,-1)=='C',]$NAMEOK='BREMERTON SCHOOL DISTRICT'
table(unlist(lapply(WAData$NAMEOK,word,-1)))
length(WAData$NAMEOK)
length(unique(WAData$NAMEOK))
names(WAData)
numericColumns =names(WAData)[4:14]
aggregateBY='NAMEOK'
(cleanWA=aggregate(WAData[,numericColumns], by=list(WAData[,aggregateBY]), sum ))
library(readxl)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/blob/gh-pages/2017WorldHappiness.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')  # file will be downloaded temporarily
library(car)
scatterplotMatrix(X2017WorldHappiness[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
summary(X2017WorldHappiness)
df=X2017WorldHappiness
length(df$Country)==length(unique(df$Country))
row.names(df)=df$Country
str(df[,c(1:6)])
library(cluster)
dfSimi=daisy(df[,c(2:6)],metric = "euclidean",
stand=TRUE) # standardizing
# input is: similary matrix
dfClus=hclust(dfSimi,method = 'average') # linkage is 'average'
# General plot
plot(dfClus,cex=0.5)
plot(dfClus,cex=0.3)
rect.hclust(dfClus, k = 4,border = c('orange','blue','red','green'))
# with 4
dfsil4=silhouette(cutree(dfClus, k = 3), dfSimi)
clust4solution=data.frame(matrix(dfsil4,ncol = 3,dimnames =dimnames(dfsil4)))
row.names(clust4solution)=df$Country
(bad4=clust4solution[clust4solution$sil_width<0,])
# with 5
dfsil5=silhouette(cutree(dfClus, k = 4), dfSimi)
clust5solution=data.frame(matrix(dfsil5,ncol = 3,dimnames =dimnames(dfsil5)))
row.names(clust5solution)=df$Country
(bad5=clust5solution[clust5solution$sil_width<0,])
intersect(row.names(bad4),row.names(bad5))
# saving solution chosen
solution=clust4solution
# creating country column
solution$Country=row.names(clust4solution)
row.names(solution)=NULL # resetting rownames
# merging
dfUpdated=merge(df,solution)
palette=c('blue','orange','red','black')
scatterplotMatrix(dfUpdated[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,groups = dfUpdated$cluster,col = palette,legend.plot=F)
hist(log(df[,7]))
# Produce a similarity matrix:
library(cluster)
dfSimi=daisy(df[,c(3:6)],metric = "euclidean",
stand=TRUE) # standardizing
# Apply the clustering technique:
dfClus=hclust(dfSimi,method = 'complete') # different linkage
# Determine the adequate amount of clusters:
# General plot
plot(dfClus,cex=0.5)
plot(dfClus,cex=0.3)
rect.hclust(dfClus, k = 4,border = c('orange','blue','red','green'))
# See numerically with 4
dfsil4=silhouette(cutree(dfClus, k = 4), dfSimi)
clust4solution=data.frame(matrix(dfsil4,ncol = 3,dimnames =dimnames(dfsil4)))
row.names(clust4solution)=df$Country
(bad4=clust4solution[clust4solution$sil_width<0,])
#Include the cluster information into your original data.
# saving solution chosen
solution=clust4solution
# creating country column
solution$Country=row.names(clust4solution)
row.names(solution)=NULL # resetting rownames
# merging
dfUpdated=merge(df,solution)
# You can see a different matrix plot:
palette=c('blue','orange','red','black')
scatterplotMatrix(dfUpdated[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,groups = dfUpdated$cluster,col = palette,legend.plot=F)
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Grad = read_excel(temp, sheet =1)
dataLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
FinanceLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
FinanceLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
finance=read.csv(FinanceLink,stringsAsFactors = F)
FinanceLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
finance=read.csv(FinanceLink,stringsAsFactors = F)
head(finance,2)
names(finance)
names(Enrollment)
Enrollment=Enrollment[,c(1,2,3,4,20)]
Enrollment=Enrollment[,c(1,2,3,4,5,20)]
Enrollment=Enrollment[,c(1,2,3,4,5)]
gradenr=merge(Enrollment,Grad,Finance,by.x='District Code',by.y="Dist",by.z="NAME"")
gradenr=merge(Enrollment,Grad,Finance,by.x='District Code',by.y="Dist",by.z="NAME")
str(indexes3)
summary(indexes3)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx"
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Grad = read_excel(temp, sheet =1)
head(Grad,2)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Enrollment = read_excel(temp, sheet =1)
head(Enrollment,2)
FinanceLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
finance=read.csv(FinanceLink,stringsAsFactors = F)
head(finance,2)
names(Enrollment)
names(Grad)
names(finance)
Enrollment=Enrollment[,c(1,2,3,4,5)]
gradenr=merge(Enrollment,Grad,Finance,by.x='District Code',by.y="Dist",by.z="NAME")
str(indexes3)
summary(indexes3)
hist(indexes3$environment)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/Grads2015.xlsx"
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Grad = read_excel(temp, sheet =1)
head(Grad,2)
temp = tempfile(fileext = ".xlsx") # use always with Excel
dataURL <- "https://github.com/awood59/data/raw/gh-pages/EnrollmentWA.xlsx" # link to data
download.file(dataURL, destfile=temp, mode='wb')
# now get it:
Enrollment = read_excel(temp, sheet =1)
head(Enrollment,2)
FinanceLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv' # link to data
finance=read.csv(FinanceLink,stringsAsFactors = F)
head(finance,2)
names(Enrollment)
names(Grad)
names(finance)
Enrollment=Enrollment[,c(1,2,3,4,5)]
gradenr=merge(Enrollment,Grad,Finance,by.x='District Code',by.y="Dist",by.z="NAME")
str(indexes3)
summary(indexes3)
View(indexes3)
knitr::opts_chunk$set(echo = TRUE)
library(car)
scatterplotMatrix(indexes3[,c(3:6)], diagonal='histogram',reg.line=NULL , smoother=NULL,legend.plot=F)
summary(indexes3)
View(indexes3)
View(finance)
