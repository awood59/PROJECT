---
title: "Governance Analytics Final Project"
author: "Alex Woodward"
date: "3/6/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Governance Analytics Final Project - Alex Woodward

## **Executive Summary:**

Here I will add a description for the executive summary. xx

## **Getting the Data**

Explain the data and where it came from.

```{r cars}
# This is the link to the first dataset. Washington State School District Graduation and Drop Out Rates

temp = tempfile(fileext = ".xlsx") 
dataURL <- "https://github.com/awood59/PROJECT/raw/master/DropOut.xlsx" 
download.file(dataURL, destfile=temp, mode='wb')

# now get it:
DropOut = read_excel(temp, sheet =1)
head(DropOut,2)
```

```{r}
## Now I will retrieve a second data file with information about Washington State Enrollment Statistics.

temp = tempfile(fileext = ".xlsx")
dataURL <- "https://github.com/awood59/PROJECT/raw/master/EnrollmentWA.xlsx" 
download.file(dataURL, destfile=temp, mode='wb')
EnrollmentWA = read_excel(temp, sheet =1)
head(EnrollmentWA,2)
```
```{r}

# Finally, one last data file. This is a file with financial statistics per school district. I will clean this data as the district names are coded with an attached number, which I need to remove before merging with the other files. In the end, I cleaned the file with Excel, but I will include information for cleaning via R below.

temp = tempfile(fileext = ".xlsx") 
dataURL <- "https://github.com/awood59/PROJECT/raw/master/WAFinance1.xlsx" 
download.file(dataURL, destfile=temp, mode='wb')
WAFinance1 = read_excel(temp, sheet =1)
head(WAFinance1,2)
```

## Data Cleaning
For the purpose of data cleaning, I first downloaded the orgingal data file. This data file had a school district column that included numbers. In order to merge the datasets, the data was cleaned to remove the numbers from the column.
```{r}
dataLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv'
```
```{r}

# Next I read the data.

theData=read.csv(dataLink,stringsAsFactors = F,strip.white = T)
```
```{r}

# Then checked the names of the columns.

names(theData)
```

```{r}

# I viewed the data counts per state.

table(theData$STATE)
```

```{r}

# Removed data that wasn't from Washington.

WAData=theData[theData$STATE=='Washington',]
row.names(WAData)=NULL
```

```{r}
# Viewed Washington Data.

WAData$NAME
```

```{r}
library(stringr)
(WAData$NAMEbad=unlist(lapply(WAData$NAME,word,-1)))
```

```{r}
WAData$NAMEOK=NA
for (pos in 1:nrow(WAData)){
    if(WAData$NAMEbad[pos]!="DISTRICT"){
    cleanValue=sub(WAData$NAMEbad[pos],'',WAData$NAME[pos])
    WAData$NAMEOK[pos]=trimws(cleanValue)
    }else{WAData$NAMEOK[pos]=WAData$NAME[pos]}}
```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```

```{r}
WAData[word(WAData$NAMEOK,-1)=='DIST',]
```

```{r}
WAData$NAMEbad=unlist(lapply(WAData$NAMEOK,word,-1))
```

```{r}
for (pos in 1:nrow(WAData)){
    if (WAData$NAMEbad[pos]=='DIST'){
        cleanValue=sub("DIST",'DISTRICT',WAData$NAMEOK[pos])
        WAData$NAMEOK[pos]=trimws(cleanValue)}}
```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```

```{r}
(lastBad=names(table(unlist(lapply(WAData$NAMEOK,word,-1))))[-c(4,5)])
```

```{r}
for (pos in 1:nrow(WAData)){
    if (WAData$NAMEbad[pos]%in% lastBad){
        cleanValue=sub(WAData$NAMEbad[pos],'',WAData$NAMEOK[pos])
        WAData$NAMEOK[pos]=trimws(cleanValue) }}

```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```
```{r}
WAData[word(WAData$NAMEOK,-1)=='C',]
```

```{r}
WAData[word(WAData$NAMEOK,-1)=='C',]$NAMEOK='BREMERTON SCHOOL DISTRICT'
```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```

```{r}
length(WAData$NAMEOK)
```

```{r}
length(unique(WAData$NAMEOK))
```

```{r}
names(WAData)
```

```{r, eval=FALSE}
numericColumns =names(WAData)[4:14]
aggregateBY='NAMEOK'
(cleanWA=aggregate(WAData[,numericColumns], by=list(WAData[,aggregateBY]), sum ))

## Including Plots.

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

## **Merging the Data**

```{r}
gradenr=merge(Enrollment,Grad,by.x='District Code',by.y="District" )
```

```{r}
# As the Enrollment and Drop Out Rate datasets both had district codes, merge via "District Code".

DropOutData <- merge(DropOut, Enrollment, by="District Code")
```

```{r}
# As the Financials and the new datasets both had district codes, merge via "District Name".

FullData <- merge(WAFinance1, DropOutData, by="District Name")
```

```{r}
# Now we can take a look at the data frame variable.

str(FullData)
```

```{r}
# Now we can look at a summary of the data.
summary(FullData)
```

```{r}
## Now I'd like to see if the updated data set has any missing values.
table(is.na(FullData))
```

```{r}
## Good, no missing values. Now I want to look at high school dropout rates.
View(FullData)

FullData$`Cohort dropout rate`
```

```{r}
# Now I will look at some descriptive statistics for State Revenues per district.

summary(FullData$'State Revenue')
```

```{r}

# Now we get the standard deviation and the coefficient of variation:
sd(FullData$'State Revenue',na.rm = T)
```
```{r}
# Coefficient of Variation
sd(FullData$'State Revenue',na.rm = T)/mean(FullData$'State Revenue',na.rm = T)
```
```{r}

# Skewness
Skew(FullData$'State Revenue',na.rm = T)
```
```{r}

# Kurtosis
Kurt(FullData$'State Revenue',na.rm = T)
```
```{r}
# keeping non missing:
data=FullData[is.finite(FullData$'Cohort dropout rate'),]
```

```{r}
# Selecting a variable
var=data$`Cohort dropout rate`

# saving mean and sd:
mnVar=mean(var,na.rm = T)
sdVar=sd(var,na.rm = T)
```
```{r}
# Selecting a variable
var2=data$`State Revenue`

# saving mean and sd:
mnVar2=mean(var2,na.rm = T)
sdVar2=sd(var2,na.rm = T)


#plotting
base = ggplot(data, aes(x=var2))
hist = base + geom_histogram(fill="green", 
                             color='grey',
                          aes(y=..density..))
```



## **Import Washington State School Districts Map**
```{r}
compressedMap= 'https://github.com/awood59/PROJECT/raw/master/tl_2013_53_unsd.zip'
```

```{r}
library(utils)
temp=tempfile()
download.file(compressedMap, temp)
unzip(temp)
```

```{r}
(maps=list.files(pattern = 'shp'))
```

```{r}
library(rgdal)
wazipMap <- rgdal::readOGR("tl_2013_53_unsd.shp",stringsAsFactors=F)
```

```{r}
plot(wazipMap,col='green')
```
## Next Step


