---
title: "Governance Analytics Final Project"
author: "Alex Woodward"
date: "3/6/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Governance Analytics Final Project - Alex Woodward

## **Executive Summary:**

Here I will add a description for the executive summary. xx

## **Getting the Data**

Explain the data and where it came from.

```{r cars}

# Libraries
library(readxl)

# This is the link to the first dataset. Washington State School District Graduation and Drop Out Rates

temp = tempfile(fileext = ".xlsx") 
dataURL <- "https://github.com/awood59/PROJECT/raw/master/DropOut.xlsx" 
download.file(dataURL, destfile=temp, mode='wb')

# now get it:
DropOut = read_excel(temp, sheet =1)
head(DropOut,2)
```

```{r}
## Now I will retrieve a second data file with information about Washington State Enrollment Statistics.

temp = tempfile(fileext = ".xlsx")
dataURL <- "https://github.com/awood59/PROJECT/raw/master/EnrollmentWA.xlsx" 
download.file(dataURL, destfile=temp, mode='wb')
EnrollmentWA = read_excel(temp, sheet =1)
head(EnrollmentWA,2)
```
```{r}

# Finally, one last data file. This is a file with financial statistics per school district. I will clean this data as the district names are coded with an attached number, which I need to remove before merging with the other files. In the end, I cleaned the file with Excel, but I will include information for cleaning via R below.

temp = tempfile(fileext = ".xlsx") 
dataURL <- "https://github.com/awood59/PROJECT/raw/master/WAFinance1.xlsx" 
download.file(dataURL, destfile=temp, mode='wb')
WAFinance1 = read_excel(temp, sheet =1)
head(WAFinance1,2)
```

## Data Cleaning
For the purpose of data cleaning, first download the orgingal data file. This data file has a school district column that includes numbers. In order to merge the datasets, the data is cleaned to remove the numbers from the column.
```{r}
dataLink='https://raw.githubusercontent.com/awood59/data/gh-pages/SchoolFinanceEdit.csv'
```
```{r}

# Now read the data.

theData=read.csv(dataLink,stringsAsFactors = F,strip.white = T)
```
```{r}

# Check the names of the columns.

names(theData)
```

```{r}

# View the data counts per state.

table(theData$STATE)
```

```{r}

# Remove data that isn't from Washington.

WAData=theData[theData$STATE=='Washington',]
row.names(WAData)=NULL
```

```{r}

# Now view Washington Data.

WAData$NAME
```

```{r}

# Now remove numbers.

library(stringr)
(WAData$NAMEbad=unlist(lapply(WAData$NAME,word,-1)))
```

```{r}

# Conintue with the rest of data cleaning.

WAData$NAMEOK=NA
for (pos in 1:nrow(WAData)){
    if(WAData$NAMEbad[pos]!="DISTRICT"){
    cleanValue=sub(WAData$NAMEbad[pos],'',WAData$NAME[pos])
    WAData$NAMEOK[pos]=trimws(cleanValue)
    }else{WAData$NAMEOK[pos]=WAData$NAME[pos]}}
```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```

```{r}
WAData[word(WAData$NAMEOK,-1)=='DIST',]
```

```{r}
WAData$NAMEbad=unlist(lapply(WAData$NAMEOK,word,-1))
```

```{r}
for (pos in 1:nrow(WAData)){
    if (WAData$NAMEbad[pos]=='DIST'){
        cleanValue=sub("DIST",'DISTRICT',WAData$NAMEOK[pos])
        WAData$NAMEOK[pos]=trimws(cleanValue)}}
```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```

```{r}
(lastBad=names(table(unlist(lapply(WAData$NAMEOK,word,-1))))[-c(4,5)])
```

```{r}
for (pos in 1:nrow(WAData)){
    if (WAData$NAMEbad[pos]%in% lastBad){
        cleanValue=sub(WAData$NAMEbad[pos],'',WAData$NAMEOK[pos])
        WAData$NAMEOK[pos]=trimws(cleanValue) }}

```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```
```{r}
WAData[word(WAData$NAMEOK,-1)=='C',]
```

```{r}
WAData[word(WAData$NAMEOK,-1)=='C',]$NAMEOK='BREMERTON SCHOOL DISTRICT'
```

```{r}
table(unlist(lapply(WAData$NAMEOK,word,-1)))
```

```{r}
length(WAData$NAMEOK)
```

```{r}
length(unique(WAData$NAMEOK))
```

```{r}
names(WAData)
```

```{r, eval=FALSE}
numericColumns =names(WAData)[4:14]
aggregateBY='NAMEOK'
(cleanWA=aggregate(WAData[,numericColumns], by=list(WAData[,aggregateBY]), sum ))

# Including Plots. You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

## **Merging the Data**

```{r}
gradenr=merge(EnrollmentWA,DropOut,by.x='District Code',by.y="District Code" )
```

```{r}
# As the Enrollment and Drop Out Rate datasets both had district codes, merge via "District Code".

DropOutData <- merge(DropOut, EnrollmentWA, by="District Code")
```

```{r}
# As the Financials and the new datasets both had district codes, merge via "District Name".

FullData <- merge(WAFinance1, DropOutData, by="District Name")
```

```{r}
# Now we can take a look at the data frame variable.

str(FullData)
```

```{r}
# Now we can look at a summary of the data.
summary(FullData)
```
```{r}
# Linear Regression of State Revenue and Dropout Rate

LinRegRevenue=lm(FullData$`State Revenue`~ `Cohort dropout rate`,y=FullData$`State Revenue`, data = FullData)

summary(LinRegRevenue)
```

```{r}
## Now we see if the updated data set has any missing values.
table(is.na(FullData))
```

```{r}
## Good, no missing values. Now look at high school dropout rates.
View(FullData)

FullData$`Cohort dropout rate`
```

```{r}
# Descriptive statistics for State Revenues per district.

summary(FullData$'State Revenue')
```

```{r}

# Standard deviation:
sd(FullData$'State Revenue',na.rm = T)
```
```{r}
# Coefficient of Variation
sd(FullData$'State Revenue',na.rm = T)/mean(FullData$'State Revenue',na.rm = T)
```
```{r}

library(DescTools)

# Skewness
Skew(FullData$'State Revenue',na.rm = T)
```
```{r}

# Kurtosis
Kurt(FullData$'State Revenue',na.rm = T)
```
```{r}

# Keeping Non Missing:
data=FullData[is.finite(FullData$'Cohort dropout rate'),]
```

```{r}

# Selecting a variable
var2=data$`State Revenue`

# Saving mean and sd:
mnVar2=mean(var2,na.rm = T)
sdVar2=sd(var2,na.rm = T)

library(ggplot2)

#Multivariate Scatter Plot State Revenue
plot(x=FullData$`Adjusted 5-Year Cohort Graduation Rate`,y=FullData$`State Revenue`) 
```
```{r}

#Multivariate Scatter Plot Local Revenue
plot(x=FullData$`Adjusted 5-Year Cohort Graduation Rate`,y=FullData$`Local Revenue`) 

```

```{r}

#Multivariate Scatter Plot Total Revenue
plot(x=FullData$`Adjusted 5-Year Cohort Graduation Rate`,y=FullData$`Total Revenue`) 
```
```{r}

# Now plot a histogram.

data=FullData[is.finite(FullData$`State Revenue`),]
```
```{r}
var=data$`State Revenue`
```
```{r}
mnVar=mean(var,na.rm = T)
sdVar=sd(var,na.rm = T)
```
```{r}
library(ggplot2)
```

```{r}
base = ggplot(data, aes(x=var))
hist = base + geom_histogram(fill="blue",
                             color='grey',
                             aes(y=..density..))
```
```{r}
histAndNormal = hist + stat_function(fun=dnorm,
                                     color="red",
                                     args=list(mean=mnVar,sd=sdVar))
```
```{r}
histAndNormal
```
```{r}

```


## **Import Washington State School Districts Map**
```{r}

# Import Map Files

compressedMap= 'https://github.com/awood59/PROJECT/raw/master/tl_2013_53_unsd.zip'
```

```{r}
library(utils)
temp=tempfile()
download.file(compressedMap, temp)
unzip(temp)
```

```{r}
(maps=list.files(pattern = 'shp'))
```

```{r}
library(rgdal)
wazipMap <- rgdal::readOGR("tl_2013_53_unsd.shp",stringsAsFactors=F)
```

```{r}
plot(wazipMap,col='green')
```
## Next Step
I will follow up by linking the map and plotting graduation rates via district.


